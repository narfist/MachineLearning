{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpamDetector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will rebuild the Algo Bag of Words in separate Steps to represent the words in the coloums with numbers. Reason: just numbers can handeld by an learning-algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  label                                        sms_message\n",
      "0   ham  Go until jurong point, crazy.. Available only ...\n",
      "1   ham                      Ok lar... Joking wif u oni...\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3   ham  U dun say so early hor... U c already then say...\n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_table('smsspamcollection/SMSSpamCollection',\n",
    "                   sep='\\t', \n",
    "                   header=None, \n",
    "                   names=['label', 'sms_message'])\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 2)\n",
      "   label                                        sms_message\n",
      "0      0  Go until jurong point, crazy.. Available only ...\n",
      "1      0                      Ok lar... Joking wif u oni...\n",
      "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3      0  U dun say so early hor... U c already then say...\n",
      "4      0  Nah I don't think he goes to usf, he lives aro...\n"
     ]
    }
   ],
   "source": [
    "# map ham and spam to 0/1 to deal with it\n",
    "df['label'] = df.label.map({'ham':0, 'spam':1})\n",
    "print(df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert to lower case\n",
      "['Hello, how are you!', 'Win money, win from home.', 'Call me now.', 'Hello, Call hello you tomorrow?']\n",
      "['hello, how are you!', 'win money, win from home.', 'call me now.', 'hello, call hello you tomorrow?']\n"
     ]
    }
   ],
   "source": [
    "print(\"Convert to lower case\")\n",
    "documents = ['Hello, how are you!',\n",
    "             'Win money, win from home.',\n",
    "             'Call me now.',\n",
    "             'Hello, Call hello you tomorrow?']\n",
    "print(documents)\n",
    "lower_case_documents = []\n",
    "for i in documents:\n",
    "    lower_case_documents.append(i.lower())\n",
    "print(lower_case_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove all punctation\n",
      "['hello how are you', 'win money win from home', 'call me now', 'hello call hello you tomorrow']\n"
     ]
    }
   ],
   "source": [
    "print(\"Remove all punctation\")\n",
    "import string\n",
    "without_punktation = []\n",
    "for i in lower_case_documents:\n",
    "    without_punktation.append(i.translate(str.maketrans('', '', string.punctuation)))\n",
    "print(without_punktation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split into single words\n",
      "[['hello', 'how', 'are', 'you'], ['win', 'money', 'win', 'from', 'home'], ['call', 'me', 'now'], ['hello', 'call', 'hello', 'you', 'tomorrow']]\n",
      "[Counter({'hello': 1, 'are': 1, 'how': 1, 'you': 1}),\n",
      " Counter({'win': 2, 'money': 1, 'from': 1, 'home': 1}),\n",
      " Counter({'call': 1, 'me': 1, 'now': 1}),\n",
      " Counter({'hello': 2, 'you': 1, 'call': 1, 'tomorrow': 1})]\n"
     ]
    }
   ],
   "source": [
    "print(\"Split into single words\")\n",
    "words = []\n",
    "for i in without_punktation:\n",
    "    words.append(i.split(' '))\n",
    "print(words)\n",
    "\n",
    "gezaehlte_Liste = []\n",
    "import pprint\n",
    "from collections import Counter\n",
    "for i in words:\n",
    "    counts = Counter(i)\n",
    "    gezaehlte_Liste.append(counts)\n",
    "pprint.pprint(gezaehlte_Liste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For now we use the ready implemented Bag of Words-Algo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First deal with test-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)\n"
     ]
    }
   ],
   "source": [
    "documents = ['Hello, how are you!',\n",
    "                'Win money, win from home.',\n",
    "                'Call me now.',\n",
    "                'Hello, Call hello you tomorrow?']\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vector = CountVectorizer()\n",
    "print(count_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['are',\n",
       " 'call',\n",
       " 'from',\n",
       " 'hello',\n",
       " 'home',\n",
       " 'how',\n",
       " 'me',\n",
       " 'money',\n",
       " 'now',\n",
       " 'tomorrow',\n",
       " 'win',\n",
       " 'you']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vector.fit(documents)\n",
    "count_vector.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform the Vector to a Matrix\n",
      "  (0, 0)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 5)\t1\n",
      "  (0, 11)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 4)\t1\n",
      "  (1, 7)\t1\n",
      "  (1, 10)\t2\n",
      "  (2, 1)\t1\n",
      "  (2, 6)\t1\n",
      "  (2, 8)\t1\n",
      "  (3, 1)\t1\n",
      "  (3, 3)\t2\n",
      "  (3, 9)\t1\n",
      "  (3, 11)\t1\n",
      "and put it in an Array\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 2, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0],\n",
       "       [0, 1, 0, 2, 0, 0, 0, 0, 0, 1, 0, 1]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Transform the Vector to a Matrix\")\n",
    "print(count_vector.transform(documents))\n",
    "print(\"and put it in an Array\")\n",
    "doc_array = count_vector.transform(documents).toarray()\n",
    "doc_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the Matrix is transformed into an Array. The frequency of every word ist represented by the count of the numbers. To make it easier to read wie transform it into an DataFrame. There we have headers with the single words.\n",
    "\n",
    "\"DataFrame([data, index, columns, dtype, copy])\tTwo-dimensional size-mutable, potentially heterogeneous tabular data structure with labeled axes (rows and columns).\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>are</th>\n",
       "      <th>call</th>\n",
       "      <th>from</th>\n",
       "      <th>hello</th>\n",
       "      <th>home</th>\n",
       "      <th>how</th>\n",
       "      <th>me</th>\n",
       "      <th>money</th>\n",
       "      <th>now</th>\n",
       "      <th>tomorrow</th>\n",
       "      <th>win</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   are  call  from  hello  home  how  me  money  now  tomorrow  win  you\n",
       "0    1     0     0      1     0    1   0      0    0         0    0    1\n",
       "1    0     0     1      0     1    0   0      1    0         0    2    0\n",
       "2    0     1     0      0     0    0   1      0    1         0    0    0\n",
       "3    0     1     0      2     0    0   0      0    0         1    0    1"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_matrix = pd.DataFrame(doc_array,\n",
    "                           columns = count_vector.get_feature_names()\n",
    "                           )\n",
    "freq_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Training and Testing Set\n",
    "Now we use the train_test_split from sklearn. First import the needed function from the framework and than use it to store the four data in separate matrices. (Train and test for message and the label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the total set: 5572\n",
      "Number of rows in the training set: 3733\n",
      "Number of rows in the test set: 1839\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df['sms_message'],\n",
    "                                                    df['label'],\n",
    "                                                    random_state=1,\n",
    "                                                    test_size = 0.33)\n",
    "#print(\"X-Train-Matrix:\"); print(X_train); print(\"X-Test-Matrix:\"); print(X_test)\n",
    "#print(\"Y-Train-Matrix:\"); print(Y_train); print(\"Y-Test-Matrix:\"); print(Y_test)\n",
    "print('Number of rows in the total set: {}' .format(df.shape[0]))\n",
    "print('Number of rows in the training set: {}'.format(X_train.shape[0]))\n",
    "print('Number of rows in the test set: {}'.format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Bag of Words to the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 686)\t1\n",
      "  (0, 3035)\t1\n",
      "  (0, 3701)\t1\n",
      "  (0, 4431)\t1\n",
      "  (0, 2734)\t1\n",
      "  (0, 875)\t1\n",
      "  (0, 6710)\t1\n",
      "  (0, 3999)\t1\n",
      "  (0, 6112)\t1\n",
      "  (0, 6171)\t1\n",
      "  (0, 3158)\t1\n",
      "  (0, 1971)\t2\n",
      "  (0, 2921)\t2\n",
      "  (0, 3039)\t1\n",
      "  (0, 956)\t1\n",
      "  (0, 6954)\t2\n",
      "  (0, 3154)\t1\n",
      "  (0, 4203)\t1\n",
      "  (1, 5625)\t1\n",
      "  (1, 5391)\t1\n",
      "  (1, 6242)\t1\n",
      "  (1, 3824)\t1\n",
      "  (1, 5837)\t1\n",
      "  (1, 5663)\t1\n",
      "  (1, 1162)\t1\n",
      "  :\t:\n",
      "  (3731, 2574)\t1\n",
      "  (3731, 237)\t1\n",
      "  (3731, 2397)\t1\n",
      "  (3731, 5442)\t1\n",
      "  (3731, 3995)\t1\n",
      "  (3731, 4638)\t1\n",
      "  (3731, 5162)\t1\n",
      "  (3731, 4242)\t1\n",
      "  (3731, 4181)\t1\n",
      "  (3731, 289)\t1\n",
      "  (3731, 6805)\t1\n",
      "  (3731, 6458)\t1\n",
      "  (3731, 337)\t1\n",
      "  (3731, 4501)\t1\n",
      "  (3731, 3502)\t1\n",
      "  (3731, 6248)\t1\n",
      "  (3731, 1472)\t1\n",
      "  (3731, 3401)\t1\n",
      "  (3731, 6242)\t1\n",
      "  (3731, 5663)\t1\n",
      "  (3731, 6112)\t1\n",
      "  (3732, 1582)\t1\n",
      "  (3732, 5633)\t1\n",
      "  (3732, 6805)\t1\n",
      "  (3732, 3978)\t1\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the CountVectorizer method\n",
    "count_vector = CountVectorizer()\n",
    "\n",
    "# Fit the training data and then return the matrix\n",
    "training_data = count_vector.fit_transform(X_train)\n",
    "\n",
    "# Transform testing data and return the matrix. Note we are not fitting the testing data into the CountVectorizer()\n",
    "testing_data = count_vector.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
